{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb3922ba",
   "metadata": {},
   "source": [
    "# ì´ë¯¸ì§€ ë¶„ë¥˜ ë©€í‹°ëª¨ë‹¬ LLM íŒŒì¸íŠœë‹ íŠœí† ë¦¬ì–¼\n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” **vLLM**ê³¼ **LLaMA-Factory**ë¥¼ í™œìš©í•˜ì—¬ ë©€í‹°ëª¨ë‹¬ LLM(MLLM)ì„ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‘ì—…ì— íŠ¹í™”ë˜ë„ë¡ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "## 1. vLLM ì„œë²„ ì‹¤í–‰ ë° ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ë¨¼ì € **Qwen2.5-VL-7B-Instruct** ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ vLLM ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "### ì‚¬ì „ ì¤€ë¹„ì‚¬í•­\n",
    "1. ğŸ¤— Hugging Faceì— ê°€ì…í•˜ì—¬ ì•¡ì„¸ìŠ¤ í† í°ì„ ë°œê¸‰ë°›ìœ¼ì„¸ìš”\n",
    "2. [Qwen2.5-VL-7B-Instruct í˜ì´ì§€](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct)ì—ì„œ ëª¨ë¸ì„ í™•ì¸í•˜ì„¸ìš”\n",
    "\n",
    "### vLLM ì„œë²„ ì‹¤í–‰ ëª…ë ¹ì–´ ì„¤ëª…\n",
    "- `HF_TOKEN`: ë°œê¸‰ë°›ì€ Hugging Face í† í°ì„ ì…ë ¥í•˜ì„¸ìš”\n",
    "- `CUDA_VISIBLE_DEVICES`: ì‚¬ìš©í•  GPU ë²ˆí˜¸ (ì „ì²´ GPU ì‚¬ìš©ì‹œ ìƒëµ ê°€ëŠ¥)  \n",
    "- `-tp`: í…ì„œ ë³‘ë ¬í™”ì— ì‚¬ìš©í•  GPU ê°œìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤\n",
    "\n",
    "**âš ï¸ ì¤‘ìš”**: ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ë³„ë„ì˜ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f2bca8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "export HF_TOKEN=<í—ˆê¹…í˜ì´ìŠ¤ í† í°>\n",
    "CUDA_VISIBLE_DEVICES=0,1 vllm serve Qwen/Qwen2.5-VL-7B-Instruct -tp 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6149476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain-openai ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",  # vLLM ì„œë²„ ì£¼ì†Œ\n",
    "    api_key=\"EMPTY\",  # vLLMì—ì„œëŠ” ì„ì˜ì˜ ê°’ ì‚¬ìš©\n",
    "    model=\"Qwen/Qwen2.5-VL-7B-Instruct\",  # ëª¨ë¸ ì´ë¦„\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "## data/image_classifiion/input.jpgë¥¼ í™œìš©í•´ë³´ì.\n",
    "image = Image.open(\"data/image_classification/input.jpg\")\n",
    "buffer = BytesIO()\n",
    "image.save(buffer, format=\"JPEG\")\n",
    "base64_image = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "# ì±„íŒ… ë©”ì‹œì§€ ë³´ë‚´ê¸°\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"ë‹¤ìŒ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì¤˜:\"},\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "        }\n",
    "    ]\n",
    ")]\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(\"AI ì‘ë‹µ:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083cac3",
   "metadata": {},
   "source": [
    "### âœ… vLLM ì„œë²„ ì‹¤í–‰ í™•ì¸\n",
    "\n",
    "í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ë¡œê·¸ê°€ ì¶œë ¥ë˜ë©´ vLLM ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‹œì‘ëœ ê²ƒì…ë‹ˆë‹¤:\n",
    "\n",
    "```log\n",
    "INFO:     Started server process [2609659]\n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "```\n",
    "\n",
    "ì´ì œ **Langchain**ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰ ì¤‘ì¸ vLLM ì„œë²„ì— ì´ë¯¸ì§€ë¥¼ í¬í•¨í•œ ë©€í‹°ëª¨ë‹¬ ìš”ì²­ì„ ë³´ë‚´ ì •ìƒ ì‘ë™ì„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76bd97c",
   "metadata": {},
   "source": [
    "### ğŸ“Š ì„œë²„ ìš”ì²­ ì²˜ë¦¬ í™•ì¸\n",
    "\n",
    "ìœ„ ì½”ë“œë¥¼ ì‹¤í–‰í•œ í›„, vLLMì„ ì‹¤í–‰ì‹œí‚¨ í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ë¡œê·¸ê°€ ì¶œë ¥ë˜ë©´ ë©€í‹°ëª¨ë‹¬ ìš”ì²­ì´ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ê²ƒì…ë‹ˆë‹¤:\n",
    "\n",
    "```log\n",
    "INFO 08-13 23:26:51 [logger.py:41] Received request chatcmpl-543715af49a8443da65b81033b0cd2de: \n",
    "prompt: '<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>ë‹¤ìŒ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì¤˜:<|im_end|>...\n",
    "INFO 08-13 23:26:51 [async_llm.py:269] Added request chatcmpl-543715af49a8443da65b81033b0cd2de.\n",
    "INFO:     127.0.0.1:39490 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
    "```\n",
    "\n",
    "## 2. ì‹¤ìŠµ ë°ì´í„°ì…‹ ë° ëª©í‘œ ì„¤ì •\n",
    "\n",
    "### ğŸ“‹ ì‚¬ìš© ë°ì´í„°ì…‹\n",
    "ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” [sfarrukhm/intel-image-classification](https://huggingface.co/datasets/sfarrukhm/intel-image-classification) ë°ì´í„°ì…‹ì„ í™œìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ¯ ì‹¤ìŠµ ëª©í‘œ\n",
    "ìì—° ì´ë¯¸ì§€ë¥¼ 6ê°œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ëŠ” ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\n",
    "\n",
    "**ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬:**\n",
    "- **Mountain** (ì‚°)\n",
    "- **Glacier** (ë¹™í•˜) \n",
    "- **Street** (ê±°ë¦¬)\n",
    "- **Sea** (ë°”ë‹¤)\n",
    "- **Forest** (ìˆ²)\n",
    "- **Buildings** (ê±´ë¬¼)\n",
    "\n",
    "ë¨¼ì € ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eb907c",
   "metadata": {},
   "source": [
    "## 3. Zero-shot ì •í™•ë„ í‰ê°€\n",
    "\n",
    "### ğŸ§ª ì‹¤í—˜ 1: ê¸°ë³¸ Zero-shot ì˜ˆì¸¡\n",
    "\n",
    "ë¨¼ì € **fine-tuning ì—†ì´** ê¸°ë³¸ Qwen2.5-VL ëª¨ë¸ì´ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868cc98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_prompt = \"ì£¼ì–´ì§„ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì‹œì˜¤: ['Mountain', 'Glacier', 'Street', 'Sea', 'Forest', 'Buildings']\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(\n",
    "        content=[{\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "        }]\n",
    "    )\n",
    "]\n",
    "\n",
    "# LLMì— ìš”ì²­\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c42c75",
   "metadata": {},
   "source": [
    "### ğŸ”§ ì‹¤í—˜ 2: Constrained Decodingìœ¼ë¡œ Zero-shot ì˜ˆì¸¡\n",
    "\n",
    "ê¸°ë³¸ zero-shot ì¶œë ¥ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "- ì •í•´ì§„ 6ê°œ ì¹´í…Œê³ ë¦¬ ì™¸ì˜ ë‹µë³€ ìƒì„±\n",
    "- ë¶ˆí•„ìš”í•œ ì„¤ëª…ì´ í¬í•¨ëœ ê¸´ ì‘ë‹µ\n",
    "- ì¼ê´€ì„± ì—†ëŠ” ì¶œë ¥ í˜•íƒœ\n",
    "\n",
    "ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **Constrained Decoding**ì„ ì‚¬ìš©í•˜ì—¬ ì¶œë ¥ì„ 6ê°œ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ê°•ì œë¡œ ì œí•œí•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1695158",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['Mountain', 'Glacier', 'Street', 'Sea', 'Forest', 'Buildings']\n",
    "\n",
    "constrained_llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",  # vLLM ì„œë²„ ì£¼ì†Œ\n",
    "    api_key=\"EMPTY\",  # vLLMì—ì„œëŠ” ì„ì˜ì˜ ê°’ ì‚¬ìš©\n",
    "    model=\"Qwen/Qwen2.5-VL-7B-Instruct\",  # ëª¨ë¸ ì´ë¦„\n",
    "    temperature=0.1,\n",
    "    extra_body={\n",
    "        \"guided_choice\": options\n",
    "    }\n",
    ")\n",
    "\n",
    "# LLMì— ìš”ì²­\n",
    "response = constrained_llm.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756c4f2",
   "metadata": {},
   "source": [
    "ì´ì œ **Fine-tuning**ì„ í†µí•´ ì´ë¯¸ì§€ ë¶„ë¥˜ ì„±ëŠ¥ì„ ê°œì„ í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913de17f",
   "metadata": {},
   "source": [
    "## 4. LLaMA-Factoryë¥¼ í™œìš©í•œ Fine-tuning\n",
    "\n",
    "### ğŸ› ï¸ í•™ìŠµ ë°ì´í„° ì¤€ë¹„\n",
    "\n",
    "ì´ì œ **LLaMA-Factory**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ë¥˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ fine-tuningì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì € ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ ë©€í‹°ëª¨ë‹¬ í•™ìŠµìš© ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì°¸ê³  ìë£Œ**: [LLaMA-Factory ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ ì„¤ì • ì˜ˆì‹œ](https://github.com/hiyouga/LLaMA-Factory/blob/main/data/mllm_demo.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a4be1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° ìƒì„± ì½”ë“œ\n",
    "python -m demo.create_image_classificat_dataset\n",
    "# ìƒì„±ëœ ë°ì´í„° í™•ì¸\n",
    "head -20 data/image_classification/train.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d1085d",
   "metadata": {},
   "source": [
    "### âš™ï¸ Fine-tuning ì‹¤í–‰\n",
    "\n",
    "ìƒì„±ëœ ë°ì´í„°ì…‹ì„ í™•ì¸í–ˆìœ¼ë‹ˆ, ì´ì œ ì‹¤ì œ fine-tuningì„ ì‹œì‘í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674d5d6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# demo/image_classification.yaml íŒŒì¼ì„ í™•ì¸í•´ë³´ì.\n",
    "CUDA_VISIBLE_DEVICES=0,1 llamafactory-cli train demo/image_classification.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf73cc",
   "metadata": {},
   "source": [
    "### ğŸš€ Fine-tuned ëª¨ë¸(LoRA) ì„œë¹™\n",
    "\n",
    "í•™ìŠµì´ ì™„ë£Œë˜ë©´ vLLMì— **LoRA ì–´ëŒ‘í„°**ë¥¼ ì¶”ê°€í•˜ì—¬ fine-tuned ëª¨ë¸ì„ ì„œë¹™í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ LoRAê°€ ì ìš©ëœ vLLM ì„œë²„ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7e3ae",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "export HF_TOKEN=<í—ˆê¹…í˜ì´ìŠ¤ í† í°>\n",
    "CUDA_VISIBLE_DEVICES=0,1 vllm serve Qwen/Qwen2.5-VL-7B-Instruct -tp 2 --enable-lora --lora-modules image_classification=$PWD/save/qwen-lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f692159e",
   "metadata": {},
   "source": [
    "## 5. ì„±ëŠ¥ ë¹„êµ ë° í‰ê°€\n",
    "\n",
    "### ğŸ” Base Model vs Fine-tuned Model ë¹„êµ\n",
    "\n",
    "vLLM ì„œë²„ê°€ LoRAì™€ í•¨ê»˜ ì‹¤í–‰ë˜ë©´, ë‹¤ìŒ ë‘ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì§ì ‘ ë¹„êµí•´ë³´ê² ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. **Base Model**: ì›ë³¸ Qwen2.5-VL-7B-Instruct\n",
    "2. **Fine-tuned Model**: LoRAê°€ ì ìš©ëœ ëª¨ë¸\n",
    "\n",
    "ë™ì¼í•œ ì…ë ¥ì— ëŒ€í•œ ë‘ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë¹„êµí•˜ì—¬ fine-tuningì˜ íš¨ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['Mountain', 'Glacier', 'Street', 'Sea', 'Forest', 'Buildings']\n",
    "\n",
    "constrained_lora_llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",  # vLLM ì„œë²„ ì£¼ì†Œ\n",
    "    api_key=\"EMPTY\",  # vLLMì—ì„œëŠ” ì„ì˜ì˜ ê°’ ì‚¬ìš©\n",
    "    model=\"image_classification\",  # Lora ì´ë¦„\n",
    "    temperature=0.1,\n",
    "    extra_body={\n",
    "        \"guided_choice\": options\n",
    "    }\n",
    ")\n",
    "\n",
    "# LLMì— ìš”ì²­\n",
    "response = constrained_lora_llm.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7641aeb0",
   "metadata": {},
   "source": [
    "### ğŸ“ ì •ëŸ‰ì  ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "í•™ìŠµì´ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ `data/image_classification/test.json`ì„ í™œìš©í•˜ì—¬ ë‘ ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ ë¹„êµí•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "**í‰ê°€ ë°©ë²•:**\n",
    "- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì˜ ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "- Base modelê³¼ Fine-tuned modelì˜ ì •í™•ë„ ì¸¡ì •\n",
    "- ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í†µí•œ íš¨ìœ¨ì ì¸ í‰ê°€ ì§„í–‰\n",
    "\n",
    "ì´ë¥¼ í†µí•´ fine-tuningì´ ì‹¤ì œë¡œ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í–ˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3302f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# test.json íŒŒì¼ ë¡œë“œ\n",
    "with open('data/image_classification/test.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"ì´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(test_data)}\")\n",
    "\n",
    "# ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ëŠ” í•¨ìˆ˜\n",
    "def encode_image_to_base64(image_path):\n",
    "    full_path = os.path.join('data', image_path)\n",
    "    image = Image.open(full_path)\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\")\n",
    "    base64_image = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    return base64_image\n",
    "\n",
    "# ë°°ì¹˜ ì˜ˆì¸¡ í•¨ìˆ˜\n",
    "def predict_batch_with_model(llm_model, image_paths, system_prompt):\n",
    "    \"\"\"ë°°ì¹˜ë¡œ ì´ë¯¸ì§€ë“¤ì„ í•œ ë²ˆì— ì²˜ë¦¬\"\"\"\n",
    "    batch_messages = []\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        base64_image = encode_image_to_base64(image_path)\n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(\n",
    "                content=[{\n",
    "                    \"type\": \"image_url\", \n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "                }]\n",
    "            )\n",
    "        ]\n",
    "        batch_messages.append(messages)\n",
    "    \n",
    "    # ë°°ì¹˜ë¡œ í•œ ë²ˆì— ì²˜ë¦¬\n",
    "    responses = llm_model.batch(batch_messages)\n",
    "    return [response.content.strip() for response in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad8c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›ë³¸ ëª¨ë¸ (ë² ì´ìŠ¤ë¼ì¸) í‰ê°€\n",
    "print(\"=== ì›ë³¸ ëª¨ë¸ (Qwen2.5-VL-7B-Instruct) í‰ê°€ ===\")\n",
    "\n",
    "options = ['Mountain', 'Glacier', 'Street', 'Sea', 'Forest', 'Buildings']\n",
    "system_prompt = \"ì£¼ì–´ì§„ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì‹œì˜¤: ['Mountain', 'Glacier', 'Street', 'Sea', 'Forest', 'Buildings']\"\n",
    "\n",
    "# ì›ë³¸ ëª¨ë¸ ì„¤ì •\n",
    "constrained_llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"EMPTY\", \n",
    "    model=\"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    temperature=0.1,\n",
    "    extra_body={\n",
    "        \"guided_choice\": options\n",
    "    }\n",
    ")\n",
    "\n",
    "correct_baseline = 0\n",
    "total_samples = len(test_data)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œ ìˆ˜ ì œí•œ (ì „ì²´ ë°ì´í„°ê°€ ë„ˆë¬´ í´ ê²½ìš°)\n",
    "batch_size = 30  # ë°°ì¹˜ í¬ê¸°\n",
    "\n",
    "print(f\"í‰ê°€í•  ìƒ˜í”Œ ìˆ˜: {total_samples}\")\n",
    "print(f\"ë°°ì¹˜ í¬ê¸°: {batch_size}\")\n",
    "\n",
    "# ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬\n",
    "for batch_start in tqdm(range(0, total_samples, batch_size), desc=\"ì›ë³¸ ëª¨ë¸ í‰ê°€ (ë°°ì¹˜)\"):\n",
    "    batch_end = min(batch_start + batch_size, total_samples)\n",
    "    batch_samples = test_data[batch_start:batch_end]\n",
    "    \n",
    "    # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„\n",
    "    batch_image_paths = [sample['images'][0] for sample in batch_samples]\n",
    "    batch_true_labels = [sample['messages'][2]['content'] for sample in batch_samples]\n",
    "    \n",
    "    # ë°°ì¹˜ ì˜ˆì¸¡\n",
    "    batch_predictions = predict_batch_with_model(constrained_llm, batch_image_paths, system_prompt)\n",
    "    \n",
    "    # ì •í™•ë„ ê³„ì‚°\n",
    "    for true_label, predicted_label in zip(batch_true_labels, batch_predictions):\n",
    "        if predicted_label == true_label:\n",
    "            correct_baseline += 1\n",
    "    \n",
    "baseline_accuracy = correct_baseline / total_samples\n",
    "print(f\"\\nì›ë³¸ ëª¨ë¸ ìµœì¢… ì •í™•ë„: {baseline_accuracy:.4f} ({correct_baseline}/{total_samples})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab20c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA ëª¨ë¸ í‰ê°€\n",
    "print(\"\\n=== LoRA ëª¨ë¸ (image_classification) í‰ê°€ ===\")\n",
    "\n",
    "# LoRA ëª¨ë¸ ì„¤ì •\n",
    "constrained_lora_llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"EMPTY\",\n",
    "    model=\"image_classification\",  # LoRA ëª¨ë¸ ì´ë¦„\n",
    "    temperature=0.1,\n",
    "    extra_body={\n",
    "        \"guided_choice\": options\n",
    "    }\n",
    ")\n",
    "\n",
    "correct_lora = 0\n",
    "\n",
    "# ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬\n",
    "for batch_start in tqdm(range(0, total_samples, batch_size), desc=\"LoRA ëª¨ë¸ í‰ê°€ (ë°°ì¹˜)\"):\n",
    "    batch_end = min(batch_start + batch_size, total_samples)\n",
    "    batch_samples = test_data[batch_start:batch_end]\n",
    "    \n",
    "    # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„\n",
    "    batch_image_paths = [sample['images'][0] for sample in batch_samples]\n",
    "    batch_true_labels = [sample['messages'][2]['content'] for sample in batch_samples]\n",
    "    \n",
    "    # ë°°ì¹˜ ì˜ˆì¸¡\n",
    "    batch_predictions = predict_batch_with_model(constrained_lora_llm, batch_image_paths, system_prompt)\n",
    "    \n",
    "    # ì •í™•ë„ ê³„ì‚°\n",
    "    for true_label, predicted_label in zip(batch_true_labels, batch_predictions):\n",
    "        if predicted_label == true_label:\n",
    "            correct_lora += 1\n",
    "    \n",
    "lora_accuracy = correct_lora / total_samples\n",
    "print(f\"\\nLoRA ëª¨ë¸ ìµœì¢… ì •í™•ë„: {lora_accuracy:.4f} ({correct_lora}/{total_samples})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ê²°ê³¼ ë¹„êµ\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ğŸ”¹ ì›ë³¸ ëª¨ë¸ ì •í™•ë„:  {baseline_accuracy:.4f} ({correct_baseline}/{total_samples})\")\n",
    "print(f\"ğŸ”¸ LoRA ëª¨ë¸ ì •í™•ë„:  {lora_accuracy:.4f} ({correct_lora}/{total_samples})\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# ì„±ëŠ¥ í–¥ìƒë„ ê³„ì‚°\n",
    "improvement = lora_accuracy - baseline_accuracy\n",
    "improvement_percent = (improvement / baseline_accuracy) * 100 if baseline_accuracy > 0 else 0\n",
    "\n",
    "if improvement > 0:\n",
    "    print(f\"âœ… LoRA ëª¨ë¸ì´ {improvement:.4f} ({improvement_percent:.2f}%) í–¥ìƒë¨\")\n",
    "elif improvement < 0:\n",
    "    print(f\"âŒ LoRA ëª¨ë¸ì´ {abs(improvement):.4f} ({abs(improvement_percent):.2f}%) í•˜ë½í•¨\")\n",
    "else:\n",
    "    print(\"ğŸŸ° ë‘ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë™ì¼í•¨\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19afda3f",
   "metadata": {},
   "source": [
    "## 6. ê²°ë¡  ë° ìš”ì•½\n",
    "\n",
    "### ğŸ¯ ì‹¤ìŠµ ê²°ê³¼ ì •ë¦¬\n",
    "\n",
    "ì´ë²ˆ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ í†µí•´ ë©€í‹°ëª¨ë‹¬ LLMì˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. **ğŸš€ vLLM ì„œë²„ ì„¤ì •**: Qwen2.5-VL-7B-Instruct ëª¨ë¸ì„ ë©€í‹°ëª¨ë‹¬ ì„œë¹™ í™˜ê²½ì—ì„œ ì‹¤í–‰\n",
    "2. **ğŸ§ª Zero-shot í‰ê°€**: Constrained decodingì„ í†µí•´ ê¸°ë³¸ ëª¨ë¸ì˜ ë¶„ë¥˜ ì„±ëŠ¥ í™•ì¸\n",
    "3. **ğŸ› ï¸ ë°ì´í„° ì¤€ë¹„**: Intel ì´ë¯¸ì§€ ë¶„ë¥˜ ë°ì´í„°ì…‹ì„ LLaMA-Factory í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "4. **ğŸ“ˆ Fine-tuning**: LoRAë¥¼ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ ëª¨ë¸ í•™ìŠµ\n",
    "5. **ğŸ“Š ì„±ëŠ¥ ë¹„êµ**: Base model vs Fine-tuned modelì˜ ì •ëŸ‰ì  í‰ê°€\n",
    "\n",
    "### ğŸ’¡ ì£¼ìš” í•™ìŠµ í¬ì¸íŠ¸\n",
    "\n",
    "- **Constrained Decoding**: ì¶œë ¥ì„ íŠ¹ì • ì„ íƒì§€ë¡œ ì œí•œí•˜ì—¬ ì¼ê´€ëœ ë¶„ë¥˜ ê²°ê³¼ í™•ë³´\n",
    "- **ë©€í‹°ëª¨ë‹¬ Fine-tuning**: í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë™ì‹œì— ì²˜ë¦¬í•˜ëŠ” ëª¨ë¸ì˜ íŠ¹í™” í•™ìŠµ\n",
    "- **LoRA ì ìš©**: ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ fine-tuningìœ¼ë¡œ ëŒ€ìš©ëŸ‰ ëª¨ë¸ ê°œì„ \n",
    "- **ë°°ì¹˜ í‰ê°€**: íš¨ìœ¨ì ì¸ ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ë° ì„±ëŠ¥ ì¸¡ì •\n",
    "\n",
    "### ğŸ”§ ì‹¤ë¬´ í™œìš© ë°©ì•ˆ\n",
    "\n",
    "ì´ ë°©ë²•ë¡ ì€ ë‹¤ìŒê³¼ ê°™ì€ ì‹¤ë¬´ ë¬¸ì œì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "- **ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ë¥˜**: ì—‘ìŠ¤ë ˆì´, MRI ë“±ì˜ ì˜ë£Œ ì˜ìƒ ì§„ë‹¨ ë³´ì¡°\n",
    "- **í’ˆì§ˆ ê²€ì‚¬**: ì œì¡°ì—…ì—ì„œì˜ ë¶ˆëŸ‰í’ˆ ìë™ ë¶„ë¥˜\n",
    "- **ì½˜í…ì¸  ëª¨ë”ë ˆì´ì…˜**: ì†Œì…œ ë¯¸ë””ì–´ ì´ë¯¸ì§€ ìë™ í•„í„°ë§\n",
    "- **ë¬¸ì„œ ë¶„ë¥˜**: ìŠ¤ìº”ëœ ë¬¸ì„œì˜ ìë™ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-factory-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
